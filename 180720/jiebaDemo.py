# jieba库概述：jieba是优秀的中文分词第三方库
# 中文文本需要通过分词获得单个的词语
# jieba是优秀的中文分词第三方库，需要额外安装
# jieba库提供三种分词模式，最简单只需掌握一个函数
# jieba库的安装 pip install jieba
# jieba分词原理：jieba分词依靠中文词库
# （1）利用一个中文词库，确定汉字之间的关联概率
# （2）汉字间概率大的组成词组，形成分词结果
# （3）除了分词,用户还可以添加词组
# 精确模式、全模式、搜索引擎模式
# 精确模式：把文本精确的切分开，不存在冗余单词
# 全模式：把文本中所有可能的词语都扫描出来，有冗余
# 搜索引擎模式：在精确模式基础上，对长词再次切分
# jieba库常用函数
# jieba.lcut(s):精确模式，返回一个列表类型的分词结果
# encoding=utf-8
import jieba

# 精确模式，返回一个列表类型的分词结果
print(jieba.lcut('中国是一个伟大的国家'))
# 全模式，返回一个列表类型的分词结果，存在冗余
print(jieba.lcut('中国是一个伟大的国家', cut_all=True))
#搜索引擎模式，返回一个列表类型的分词结果，存在冗余
print(jieba.lcut_for_search('中华人民共和国是伟大的'))
#向分词词典增加新词w
print(jieba.add_word('蟒蛇语言'))
